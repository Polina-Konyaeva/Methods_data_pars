{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f292b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findChildren'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0c801ace2fb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#hh.ru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mhunt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://hh.ru'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Python'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hunter.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mht\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-0c801ace2fb1>\u001b[0m in \u001b[0;36mhh\u001b[1;34m(main_link, search_str, n_str)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mjobs_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_html\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'vacancy-serp'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mjobs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjobs_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindChildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjobs_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mjob_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findChildren'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "from pprint import pprint\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "headers = {'User-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/80.0.3987.87 Chrome/80.0.3987.87 Safari/537.36'}\n",
    "\n",
    "def hh(main_link, search_str, n_str):\n",
    "    html = requests.get(main_link+'/search/vacancy?clusters=true&enable_snippets=true&text='+search_str+'&showClusters=true',headers=headers).text\n",
    "    parsed_html = bs(html,'lxml')\n",
    "    jobs = []\n",
    "    for i in range(n_str):\n",
    "        jobs_block = parsed_html.find('div',{'class':'vacancy-serp'})\n",
    "        jobs_list = jobs_block.findChildren(recursive=False)\n",
    "        for job in jobs_list:\n",
    "            job_data={}\n",
    "            req=job.find('span',{'class':'g-user-content'})\n",
    "            if req!=None:\n",
    "                main_info = req.findChild()\n",
    "                job_name = main_info.getText()\n",
    "                job_link = main_info['href']\n",
    "                salary = job.find('div',{'class':'vacancy-serp-item__compensation'})\n",
    "                if not salary:\n",
    "                    salary_min=0\n",
    "                    salary_max=0\n",
    "                else:\n",
    "                    salary=salary.getText().replace(u'\\xa0', u' ')\n",
    "                    salaries=salary.split('-')\n",
    "                    salary_min=salaries[0]\n",
    "                    if len(salaries)>1:\n",
    "                        salary_max=salaries[1]\n",
    "                    else:\n",
    "                        salary_max=''\n",
    "                job_data['name'] = job_name\n",
    "                job_data['salary_min'] = salary_min\n",
    "                job_data['salary_max'] = salary_max\n",
    "                job_data['link'] = job_link\n",
    "                job_data['site'] = main_link\n",
    "                jobs.append(job_data)\n",
    "        time.sleep(1)\n",
    "        next_btn_block=parsed_html.find('a',{'class':'bloko-button HH-Pager-Controls-Next HH-Pager-Control'})\n",
    "        next_btn_link=next_btn_block['href']\n",
    "        html = requests.get(main_link+next_btn_link,headers=headers).text\n",
    "        parsed_html = bs(html,'lxml')\n",
    "    return jobs\n",
    "\n",
    "#hh.ru\n",
    "\n",
    "hunt=hh('https://hh.ru','Python',4)\n",
    "\n",
    "with open('hunter.json','w') as ht:\n",
    "  json.dump(hunt,ht)\n",
    "pd.read_json('hunter.json')\n",
    "\n",
    "def parser_superjob(vacancy):\n",
    "    vacancy_date = []\n",
    "    \n",
    "    params = {\n",
    "        'keywords': vacancy, \n",
    "        'profession_only': '1',\n",
    "        'geo[c][0]': '15', \n",
    "        'geo[c][1]': '1', \n",
    "        'geo[c][2]': '9', \n",
    "        'page': ''\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'User-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/80.0.3987.87 Chrome/80.0.3987.87 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    link = 'https://www.superjob.ru/vacancy/search/'\n",
    "       \n",
    "    html = requests.get(link, params=params, headers=headers)\n",
    "    \n",
    "    if html.ok:\n",
    "        parsed_html = bs(html.text,'lxml')\n",
    "    \n",
    "        page_block = parsed_html.find('a', {'class': 'f-test-button-1'})\n",
    "    if not page_block:\n",
    "        last_page = 1\n",
    "    else:\n",
    "        page_block = page_block.findParent()\n",
    "        last_page = int(page_block.find_all('a')[-2].getText())\n",
    "    \n",
    "    for page in range(0, last_page + 1):\n",
    "        params['page'] = page\n",
    "        html = requests.get(link, params=params, headers=headers)\n",
    "        \n",
    "        if html.ok:\n",
    "            parsed_html = bs(html.text,'html.parser')\n",
    "            vacancy_items = parsed_html.find_all('div', {'class': 'f-test-vacancy-item'})\n",
    "                        \n",
    "            for item in vacancy_items:\n",
    "                vacancy_date.append(parser_item_superjob(item))\n",
    "                \n",
    "    return vacancy_date\n",
    "\n",
    "def parser_item_superjob(item):\n",
    "\n",
    "    vacancy_date = {}\n",
    "    \n",
    "    vacancy_name = item.find_all('a')\n",
    "    if len(vacancy_name) > 1:\n",
    "        vacancy_name = vacancy_name[-2].getText()\n",
    "    else:\n",
    "        vacancy_name = vacancy_name[0].getText()\n",
    "    vacancy_date['vacancy_name'] = vacancy_name\n",
    "    \n",
    "    salary = item.find('span', {'class': 'f-test-text-company-item-salary'}).findChildren()\n",
    "    if not salary:\n",
    "        salary_min = None\n",
    "        salary_max = None\n",
    "        salary_currency = None\n",
    "    else:\n",
    "        salary_currency = salary[-1].getText()\n",
    "        is_check_sarary = item.find('span', {'class': 'f-test-text-company-item-salary'}).getText().replace(u'\\xa0', u' ').split(' ', 1)[0]\n",
    "        if is_check_sarary == 'до' or len(salary) == 2:\n",
    "            salary_min = None\n",
    "            salary_max = int(salary[0].getText().replace(u'\\xa0', u''))\n",
    "        elif is_check_sarary == 'от':\n",
    "            salary_min = int(salary[0].getText().replace(u'\\xa0', u''))\n",
    "            salary_max = None\n",
    "        else:\n",
    "            salary_min = int(salary[0].getText().replace(u'\\xa0', u''))\n",
    "            salary_max = int(salary[2].getText().replace(u'\\xa0', u''))           \n",
    "        \n",
    "    vacancy_date['salary_min'] = salary_min\n",
    "    vacancy_date['salary_max'] = salary_max\n",
    "    vacancy_date['salary_currency'] = salary_currency\n",
    "    \n",
    "    vacancy_link = item.find_all('a')\n",
    "    \n",
    "    if len(vacancy_link) > 1:\n",
    "        vacancy_link = vacancy_link[-2]['href']\n",
    "    else:\n",
    "        vacancy_link = vacancy_link[0]['href']\n",
    "    \n",
    "    vacancy_date['vacancy_link'] = f'https://www.superjob.ru{vacancy_link }'\n",
    "    vacancy_date['site'] = 'www.superjob.ru'\n",
    "    return vacancy_date\n",
    "\n",
    "vacancy = 'Python'\n",
    "df = parser_superjob(vacancy)\n",
    "with open('jobs.json','w') as t:\n",
    "  json.dump(df,t)\n",
    "pd.read_json('jobs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c51f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
